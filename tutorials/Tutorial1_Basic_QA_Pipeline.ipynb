{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahutE7Upp3sv"
      },
      "source": [
        "# Build Your First QA System\n",
        "\n",
        "<img style=\"float: right;\" src=\"https://upload.wikimedia.org/wikipedia/en/d/d8/Game_of_Thrones_title_card.jpg\">\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deepset-ai/haystack/blob/master/tutorials/Tutorial1_Basic_QA_Pipeline.ipynb)\n",
        "\n",
        "Question Answering can be used in a variety of use cases. A very common one:  Using it to navigate through complex knowledge bases or long documents (\"search setting\").\n",
        "\n",
        "A \"knowledge base\" could for example be your website, an internal wiki or a collection of financial reports. \n",
        "In this tutorial we will work on a slightly different domain: \"Game of Thrones\". \n",
        "\n",
        "Let's see how we can use a bunch of Wikipedia articles to answer a variety of questions about the \n",
        "marvellous seven kingdoms.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "aeWvJvVzp3sy"
      },
      "source": [
        "### Prepare environment\n",
        "\n",
        "#### Colab: Enable the GPU runtime\n",
        "Make sure you enable the GPU runtime to experience decent speed in this tutorial.\n",
        "**Runtime -> Change Runtime type -> Hardware accelerator -> GPU**\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/deepset-ai/haystack/master/docs/img/colab_gpu_runtime.jpg\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "3IXn76Vlp3sz",
        "outputId": "ca1f18b3-4683-47c9-ba31-bdc023244ffa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Make sure you have a GPU running\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DKBSm6CCp3s0",
        "outputId": "c47cbd5d-80a4-43bb-f36a-5922fbbf9420",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Collecting pip\n",
            "  Downloading pip-22.0.4-py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 5.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "Successfully installed pip-22.0.4\n",
            "Collecting farm-haystack[colab]\n",
            "  Cloning https://github.com/deepset-ai/haystack.git to /tmp/pip-install-7zvuexeg/farm-haystack_4b1c573804eb453281095b07ececf5b4\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/deepset-ai/haystack.git /tmp/pip-install-7zvuexeg/farm-haystack_4b1c573804eb453281095b07ececf5b4\n",
            "  Resolved https://github.com/deepset-ai/haystack.git to commit 25475a68c77aaa12a7af4f2cf74e3fc23205f03f\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mlflow<=1.13.1\n",
            "  Downloading mlflow-1.13.1-py3-none-any.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from farm-haystack[colab]) (4.64.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from farm-haystack[colab]) (1.0.2)\n",
            "Collecting pydantic\n",
            "  Downloading pydantic-1.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from farm-haystack[colab]) (4.3.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from farm-haystack[colab]) (3.2.5)\n",
            "Collecting mmh3\n",
            "  Downloading mmh3-3.0.0-cp37-cp37m-manylinux2010_x86_64.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 KB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz\n",
            "  Downloading rapidfuzz-2.0.10-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.7/dist-packages (from farm-haystack[colab]) (1.4.1)\n",
            "Collecting posthog\n",
            "  Downloading posthog-1.4.6-py2.py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from farm-haystack[colab]) (4.11.3)\n",
            "Collecting azure-core<1.23\n",
            "  Downloading azure_core-1.22.1-py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.6/178.6 KB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentence-transformers>=2.2.0\n",
            "  Downloading sentence-transformers-2.2.0.tar.gz (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.7/79.7 KB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from farm-haystack[colab]) (8.12.0)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 KB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python-docx\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch<1.11,>1.9 in /usr/local/lib/python3.7/dist-packages (from farm-haystack[colab]) (1.10.0+cu111)\n",
            "Collecting quantulum3\n",
            "  Downloading quantulum3-0.7.10-py3-none-any.whl (10.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 KB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tika\n",
            "  Downloading tika-1.24.tar.gz (28 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting elastic-apm\n",
            "  Downloading elastic_apm-6.9.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (374 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.7/374.7 KB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==4.13.0\n",
            "  Downloading transformers-4.13.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from farm-haystack[colab]) (2.23.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from farm-haystack[colab]) (0.3.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from farm-haystack[colab]) (2.6.3)\n",
            "Collecting azure-ai-formrecognizer==3.2.0b2\n",
            "  Downloading azure_ai_formrecognizer-3.2.0b2-py2.py3-none-any.whl (219 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.7/219.7 KB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting elasticsearch<=7.10,>=7.7\n",
            "  Downloading elasticsearch-7.10.0-py2.py3-none-any.whl (321 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.8/321.8 KB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from farm-haystack[colab]) (1.3.5)\n",
            "Collecting grpcio==1.43.0\n",
            "  Downloading grpcio-1.43.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from azure-ai-formrecognizer==3.2.0b2->farm-haystack[colab]) (1.15.0)\n",
            "Collecting msrest>=0.6.21\n",
            "  Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.2/85.2 KB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-common~=1.1\n",
            "  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 KB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m895.2/895.2 KB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0->farm-haystack[colab]) (3.6.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m596.3/596.3 KB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0->farm-haystack[colab]) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0->farm-haystack[colab]) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0->farm-haystack[colab]) (1.21.6)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from elasticsearch<=7.10,>=7.7->farm-haystack[colab]) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<2,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from elasticsearch<=7.10,>=7.7->farm-haystack[colab]) (1.24.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from mlflow<=1.13.1->farm-haystack[colab]) (1.3.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from mlflow<=1.13.1->farm-haystack[colab]) (0.4)\n",
            "Collecting alembic<=1.4.1\n",
            "  Downloading alembic-1.4.1.tar.gz (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting prometheus-flask-exporter\n",
            "  Downloading prometheus_flask_exporter-0.20.1-py3-none-any.whl (18 kB)\n",
            "Collecting gunicorn\n",
            "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 KB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-storage-blob>=12.0.0\n",
            "  Downloading azure_storage_blob-12.11.0-py3-none-any.whl (346 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.4/346.4 KB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting databricks-cli>=0.8.7\n",
            "  Downloading databricks-cli-0.16.6.tar.gz (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.2/62.2 KB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gitpython>=2.1.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.2/181.2 KB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from mlflow<=1.13.1->farm-haystack[colab]) (0.4.2)\n",
            "Collecting docker>=4.0.0\n",
            "  Downloading docker-5.0.3-py2.py3-none-any.whl (146 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.2/146.2 KB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow<=1.13.1->farm-haystack[colab]) (7.1.2)\n",
            "Requirement already satisfied: Flask in /usr/local/lib/python3.7/dist-packages (from mlflow<=1.13.1->farm-haystack[colab]) (1.1.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from mlflow<=1.13.1->farm-haystack[colab]) (2.8.2)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from mlflow<=1.13.1->farm-haystack[colab]) (3.17.3)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.7/dist-packages (from mlflow<=1.13.1->farm-haystack[colab]) (1.4.35)\n",
            "Collecting querystring-parser\n",
            "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->farm-haystack[colab]) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->farm-haystack[colab]) (3.0.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->farm-haystack[colab]) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->farm-haystack[colab]) (3.1.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=2.2.0->farm-haystack[colab]) (0.11.1+cu111)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<1.11,>1.9->farm-haystack[colab]) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->farm-haystack[colab]) (3.8.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->farm-haystack[colab]) (5.7.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->farm-haystack[colab]) (0.18.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->farm-haystack[colab]) (21.4.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->farm-haystack[colab]) (2022.1)\n",
            "Collecting monotonic>=1.5\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff<2.0.0,>=1.10.0\n",
            "  Downloading backoff-1.11.1-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from python-docx->farm-haystack[colab]) (4.2.6)\n",
            "Collecting num2words\n",
            "  Downloading num2words-0.5.10-py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 KB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: inflect in /usr/local/lib/python3.7/dist-packages (from quantulum3->farm-haystack[colab]) (2.1.0)\n",
            "Collecting jarowinkler<1.1.0,>=1.0.2\n",
            "  Downloading jarowinkler-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (103 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.4/103.4 KB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tika->farm-haystack[colab]) (57.4.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.0-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 KB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-editor>=0.3\n",
            "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
            "Collecting cryptography>=2.1.4\n",
            "  Downloading cryptography-36.0.2-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyjwt>=1.7.0\n",
            "  Downloading PyJWT-2.3.0-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow<=1.13.1->farm-haystack[colab]) (3.2.0)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow<=1.13.1->farm-haystack[colab]) (0.8.9)\n",
            "Collecting websocket-client>=0.32.0\n",
            "  Downloading websocket_client-1.3.2-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.3/54.3 KB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 KB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting isodate>=0.6.0\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 KB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from msrest>=0.6.21->azure-ai-formrecognizer==3.2.0b2->farm-haystack[colab]) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.13.0->farm-haystack[colab]) (3.0.8)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->mlflow<=1.13.1->farm-haystack[colab]) (1.1.2)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow<=1.13.1->farm-haystack[colab]) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow<=1.13.1->farm-haystack[colab]) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow<=1.13.1->farm-haystack[colab]) (1.0.1)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.7/dist-packages (from num2words->quantulum3->farm-haystack[colab]) (0.6.2)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from prometheus-flask-exporter->mlflow<=1.13.1->farm-haystack[colab]) (0.14.1)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers>=2.2.0->farm-haystack[colab]) (7.1.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.1.4->azure-storage-blob>=12.0.0->mlflow<=1.13.1->farm-haystack[colab]) (1.15.0)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask->mlflow<=1.13.1->farm-haystack[colab]) (2.0.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob>=12.0.0->mlflow<=1.13.1->farm-haystack[colab]) (2.21)\n",
            "Building wheels for collected packages: sentence-transformers, farm-haystack, langdetect, python-docx, seqeval, tika, alembic, databricks-cli\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.0-py3-none-any.whl size=120747 sha256=697a23ae570486d93b03a84fa8f862b66e26131265e38834a841cf177dddbcca\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/c0/df/b6873ab7aac3f2465aa9144b6b4c41c4391cfecc027c8b07e7\n",
            "  Building wheel for farm-haystack (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for farm-haystack: filename=farm_haystack-1.3.1rc0-py3-none-any.whl size=497442 sha256=ab39f9522efce87e2a8f0c69c71a56592e2cfcc91c15f44ff7e100020d07ed4f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0zj4bq3h/wheels/a7/05/3b/9b33368d9af06a39f8e6af2e97fa2af876e893ade323cfc2c9\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=2d2f916d910654334d882b83135798c55ce9944a1c8ebddaeee47b528b9739c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184507 sha256=0d8b94e20089934c3f81aaba80b68ddef8a841bb65940fbfbaea7687e76d4f86\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/6f/b9/d798122a8b55b74ad30b5f52b01482169b445fbb84a11797a6\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=7ed43fa5be22f332af461d28bb0e1d14f33128012275514a916bb912514086e3\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "  Building wheel for tika (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tika: filename=tika-1.24-py3-none-any.whl size=32893 sha256=8c69d4b909213f26daff8c6ed3b00a1989648968d2de233a5061730b652bf24b\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/2b/38/58ff05467a742e32f67f5d0de048fa046e764e2fbb25ac93f3\n",
            "  Building wheel for alembic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for alembic: filename=alembic-1.4.1-py2.py3-none-any.whl size=158171 sha256=8a6b8173643f12f45a5f84f220e5a4b3736c3669471e62c6a1e4724ebd16285a\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/5d/0a/9e13f53f4f5dfb67cd8d245bb7cdffe12f135846f491a283e3\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for databricks-cli: filename=databricks_cli-0.16.6-py3-none-any.whl size=112631 sha256=2d505ab5189852ed6fa9f8aa94378ad4bf195486376f6782d0dd3184529d91eb\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/c1/f8/d75a22e789ab6a4dff11f18338c3af4360189aa371295cc934\n",
            "Successfully built sentence-transformers farm-haystack langdetect python-docx seqeval tika alembic databricks-cli\n",
            "Installing collected packages: tokenizers, sentencepiece, python-editor, monotonic, mmh3, azure-common, websocket-client, smmap, sacremoses, querystring-parser, pyyaml, python-docx, pyjwt, pydantic, num2words, langdetect, jarowinkler, isodate, gunicorn, grpcio, elasticsearch, elastic-apm, backoff, tika, rapidfuzz, quantulum3, posthog, Mako, huggingface-hub, gitdb, docker, databricks-cli, cryptography, azure-core, transformers, seqeval, prometheus-flask-exporter, msrest, gitpython, alembic, sentence-transformers, azure-storage-blob, azure-ai-formrecognizer, mlflow, farm-haystack\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.44.0\n",
            "    Uninstalling grpcio-1.44.0:\n",
            "      Successfully uninstalled grpcio-1.44.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Mako-1.2.0 alembic-1.4.1 azure-ai-formrecognizer-3.2.0b2 azure-common-1.1.28 azure-core-1.22.1 azure-storage-blob-12.11.0 backoff-1.11.1 cryptography-36.0.2 databricks-cli-0.16.6 docker-5.0.3 elastic-apm-6.9.1 elasticsearch-7.10.0 farm-haystack-1.3.1rc0 gitdb-4.0.9 gitpython-3.1.27 grpcio-1.43.0 gunicorn-20.1.0 huggingface-hub-0.5.1 isodate-0.6.1 jarowinkler-1.0.2 langdetect-1.0.9 mlflow-1.13.1 mmh3-3.0.0 monotonic-1.6 msrest-0.6.21 num2words-0.5.10 posthog-1.4.6 prometheus-flask-exporter-0.20.1 pydantic-1.9.0 pyjwt-2.3.0 python-docx-0.8.11 python-editor-1.0.4 pyyaml-6.0 quantulum3-0.7.10 querystring-parser-1.2.4 rapidfuzz-2.0.10 sacremoses-0.0.49 sentence-transformers-2.2.0 sentencepiece-0.1.96 seqeval-1.2.2 smmap-5.0.0 tika-1.24 tokenizers-0.10.3 transformers-4.13.0 websocket-client-1.3.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Install the latest release of Haystack in your own environment\n",
        "#! pip install farm-haystack\n",
        "\n",
        "# Install the latest master of Haystack\n",
        "!pip install --upgrade pip\n",
        "!pip install git+https://github.com/deepset-ai/haystack.git#egg=farm-haystack[colab]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mdpB6nzYp3s1",
        "outputId": "bc04325f-bf58-45b9-8b39-8fb9f46beec6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO - haystack.modeling.model.optimization -  apex not found, won't use it. See https://nvidia.github.io/apex/\n",
            "ERROR - root -  Failed to import 'magic' (from 'python-magic' and 'python-magic-bin' on Windows). FileTypeClassifier will not perform mimetype detection on extensionless files. Please make sure the necessary OS libraries are installed if you need this functionality.\n"
          ]
        }
      ],
      "source": [
        "from haystack.utils import clean_wiki_text, convert_files_to_docs, fetch_archive_from_http, print_answers\n",
        "from haystack.nodes import FARMReader, TransformersReader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQC8kfuCp3s1"
      },
      "source": [
        "## Document Store\n",
        "\n",
        "Haystack finds answers to queries within the documents stored in a `DocumentStore`. The current implementations of `DocumentStore` include `ElasticsearchDocumentStore`, `FAISSDocumentStore`,  `SQLDocumentStore`, and `InMemoryDocumentStore`.\n",
        "\n",
        "**Here:** We recommended Elasticsearch as it comes preloaded with features like [full-text queries](https://www.elastic.co/guide/en/elasticsearch/reference/current/full-text-queries.html), [BM25 retrieval](https://www.elastic.co/elasticon/conf/2016/sf/improved-text-scoring-with-bm25), and [vector storage for text embeddings](https://www.elastic.co/guide/en/elasticsearch/reference/7.6/dense-vector.html).\n",
        "\n",
        "**Alternatives:** If you are unable to setup an Elasticsearch instance, then follow the [Tutorial 3](https://github.com/deepset-ai/haystack/blob/master/tutorials/Tutorial3_Basic_QA_Pipeline_without_Elasticsearch.ipynb) for using SQL/InMemory document stores.\n",
        "\n",
        "**Hint**: This tutorial creates a new document store instance with Wikipedia articles on Game of Thrones. However, you can configure Haystack to work with your existing document stores.\n",
        "\n",
        "### Start an Elasticsearch server\n",
        "You can start Elasticsearch on your local machine instance using Docker. If Docker is not readily available in your environment (e.g. in Colab notebooks), then you can manually download and execute Elasticsearch from source."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XZ6w5264p3s2",
        "outputId": "5a167f7e-1182-4843-fa11-96cb0824f0c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING - haystack.utils.doc_store -  Tried to start Elasticsearch through Docker but this failed. It is likely that there is already an existing Elasticsearch instance running. \n"
          ]
        }
      ],
      "source": [
        "# Recommended: Start Elasticsearch using Docker via the Haystack utility function\n",
        "from haystack.utils import launch_es\n",
        "\n",
        "launch_es()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJbsLPKpp3s3"
      },
      "outputs": [],
      "source": [
        "# In Colab / No Docker environments: Start Elasticsearch from source\n",
        "! wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.9.2-linux-x86_64.tar.gz -q\n",
        "! tar -xzf elasticsearch-7.9.2-linux-x86_64.tar.gz\n",
        "! chown -R daemon:daemon elasticsearch-7.9.2\n",
        "\n",
        "import os\n",
        "from subprocess import Popen, PIPE, STDOUT\n",
        "\n",
        "es_server = Popen(\n",
        "    [\"elasticsearch-7.9.2/bin/elasticsearch\"], stdout=PIPE, stderr=STDOUT, preexec_fn=lambda: os.setuid(1)  # as daemon\n",
        ")\n",
        "# wait until ES has started\n",
        "! sleep 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "-vovdBflp3s3"
      },
      "outputs": [],
      "source": [
        "# Connect to Elasticsearch\n",
        "\n",
        "from haystack.document_stores import ElasticsearchDocumentStore\n",
        "\n",
        "document_store = ElasticsearchDocumentStore(host=\"localhost\", username=\"\", password=\"\", index=\"document\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "X_jmnlejp3s4"
      },
      "source": [
        "## Preprocessing of documents\n",
        "\n",
        "Haystack provides a customizable pipeline for:\n",
        " - converting files into texts\n",
        " - cleaning texts\n",
        " - splitting texts\n",
        " - writing them to a Document Store\n",
        "\n",
        "In this tutorial, we download Wikipedia articles about Game of Thrones, apply a basic cleaning function, and index them in Elasticsearch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Ja0VEh_tp3s4"
      },
      "outputs": [],
      "source": [
        "# Let's first fetch some documents that we want to query\n",
        "# Here: 517 Wikipedia articles for Game of Thrones\n",
        "doc_dir = \"data/tutorial1\"\n",
        "s3_url = \"https://s3.eu-central-1.amazonaws.com/deepset.ai-farm-qa/datasets/documents/wiki_gameofthrones_txt1.zip\"\n",
        "fetch_archive_from_http(url=s3_url, output_dir=doc_dir)\n",
        "\n",
        "# Convert files to dicts\n",
        "# You can optionally supply a cleaning function that is applied to each doc (e.g. to remove footers)\n",
        "# It must take a str as input, and return a str.\n",
        "docs = convert_files_to_docs(dir_path=doc_dir, clean_func=clean_wiki_text, split_paragraphs=True)\n",
        "\n",
        "# We now have a list of dictionaries that we can write to our document store.\n",
        "# If your texts come from a different source (e.g. a DB), you can of course skip convert_files_to_dicts() and create the dictionaries yourself.\n",
        "# The default format here is:\n",
        "# {\n",
        "#    'content': \"<DOCUMENT_TEXT_HERE>\",\n",
        "#    'meta': {'name': \"<DOCUMENT_NAME_HERE>\", ...}\n",
        "# }\n",
        "# (Optionally: you can also add more key-value-pairs here, that will be indexed as fields in Elasticsearch and\n",
        "# can be accessed later for filtering or shown in the responses of the Pipeline)\n",
        "\n",
        "# Let's have a look at the first 3 entries:\n",
        "print(docs[:3])\n",
        "\n",
        "# Now, let's write the dicts containing documents to our DB.\n",
        "document_store.write_documents(docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVjTUI0Pp3s4"
      },
      "source": [
        "## Initalize Retriever, Reader,  & Pipeline\n",
        "\n",
        "### Retriever\n",
        "\n",
        "Retrievers help narrowing down the scope for the Reader to smaller units of text where a given question could be answered.\n",
        "They use some simple but fast algorithm.\n",
        "\n",
        "**Here:** We use Elasticsearch's default BM25 algorithm\n",
        "\n",
        "**Alternatives:**\n",
        "\n",
        "- Customize the `ElasticsearchRetriever`with custom queries (e.g. boosting) and filters\n",
        "- Use `TfidfRetriever` in combination with a SQL or InMemory Document store for simple prototyping and debugging\n",
        "- Use `EmbeddingRetriever` to find candidate documents based on the similarity of embeddings (e.g. created via Sentence-BERT)\n",
        "- Use `DensePassageRetriever` to use different embedding models for passage and query (see Tutorial 6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xp3JP55Ip3s5"
      },
      "outputs": [],
      "source": [
        "from haystack.nodes import ElasticsearchRetriever\n",
        "\n",
        "retriever = ElasticsearchRetriever(document_store=document_store)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "BVHkjPpRp3s5"
      },
      "outputs": [],
      "source": [
        "# Alternative: An in-memory TfidfRetriever based on Pandas dataframes for building quick-prototypes with SQLite document store.\n",
        "\n",
        "# from haystack.nodes import TfidfRetriever\n",
        "# retriever = TfidfRetriever(document_store=document_store)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sY-1gktp3s5"
      },
      "source": [
        "### Reader\n",
        "\n",
        "A Reader scans the texts returned by retrievers in detail and extracts the k best answers. They are based\n",
        "on powerful, but slower deep learning models.\n",
        "\n",
        "Haystack currently supports Readers based on the frameworks FARM and Transformers.\n",
        "With both you can either load a local model or one from Hugging Face's model hub (https://huggingface.co/models).\n",
        "\n",
        "**Here:** a medium sized RoBERTa QA model using a Reader based on FARM (https://huggingface.co/deepset/roberta-base-squad2)\n",
        "\n",
        "**Alternatives (Reader):** TransformersReader (leveraging the `pipeline` of the Transformers package)\n",
        "\n",
        "**Alternatives (Models):** e.g. \"distilbert-base-uncased-distilled-squad\" (fast) or \"deepset/bert-large-uncased-whole-word-masking-squad2\" (good accuracy)\n",
        "\n",
        "**Hint:** You can adjust the model to return \"no answer possible\" with the no_ans_boost. Higher values mean the model prefers \"no answer possible\"\n",
        "\n",
        "#### FARMReader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "cUvrDf5up3s6"
      },
      "outputs": [],
      "source": [
        "# Load a  local model or any of the QA models on\n",
        "# Hugging Face's model hub (https://huggingface.co/models)\n",
        "\n",
        "reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", use_gpu=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5JixVMbp3s6"
      },
      "source": [
        "#### TransformersReader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vsHCSVGip3s6"
      },
      "outputs": [],
      "source": [
        "# Alternative:\n",
        "# reader = TransformersReader(model_name_or_path=\"distilbert-base-uncased-distilled-squad\", tokenizer=\"distilbert-base-uncased\", use_gpu=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWwlV0Ncp3s6"
      },
      "source": [
        "### Pipeline\n",
        "\n",
        "With a Haystack `Pipeline` you can stick together your building blocks to a search pipeline.\n",
        "Under the hood, `Pipelines` are Directed Acyclic Graphs (DAGs) that you can easily customize for your own use cases.\n",
        "To speed things up, Haystack also comes with a few predefined Pipelines. One of them is the `ExtractiveQAPipeline` that combines a retriever and a reader to answer our questions.\n",
        "You can learn more about `Pipelines` in the [docs](https://haystack.deepset.ai/docs/latest/pipelinesmd)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "bIhc7ceqp3s6"
      },
      "outputs": [],
      "source": [
        "from haystack.pipelines import ExtractiveQAPipeline\n",
        "\n",
        "pipe = ExtractiveQAPipeline(reader, retriever)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sMmFFqMp3s7"
      },
      "source": [
        "## Voilà! Ask a question!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "jcVXC0mcp3s7"
      },
      "outputs": [],
      "source": [
        "# You can configure how many candidates the reader and retriever shall return\n",
        "# The higher top_k_retriever, the better (but also the slower) your answers.\n",
        "prediction = pipe.run(\n",
        "    query=\"Who is the father of Arya Stark?\", params={\"Retriever\": {\"top_k\": 10}, \"Reader\": {\"top_k\": 5}}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxZfyiMIp3s7"
      },
      "outputs": [],
      "source": [
        "# prediction = pipe.run(query=\"Who created the Dothraki vocabulary?\", params={\"Reader\": {\"top_k\": 5}})\n",
        "# prediction = pipe.run(query=\"Who is the sister of Sansa?\", params={\"Reader\": {\"top_k\": 5}})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4u5uqC2p3s7"
      },
      "outputs": [],
      "source": [
        "# Now you can either print the object directly...\n",
        "from pprint import pprint\n",
        "\n",
        "pprint(prediction)\n",
        "\n",
        "# Sample output:\n",
        "# {\n",
        "#     'answers': [ <Answer: answer='Eddard', type='extractive', score=0.9919578731060028, offsets_in_document=[{'start': 608, 'end': 615}], offsets_in_context=[{'start': 72, 'end': 79}], document_id='cc75f739897ecbf8c14657b13dda890e', meta={'name': '454_Music_of_Game_of_Thrones.txt'}}, context='...' >,\n",
        "#                  <Answer: answer='Ned', type='extractive', score=0.9767240881919861, offsets_in_document=[{'start': 3687, 'end': 3801}], offsets_in_context=[{'start': 18, 'end': 132}], document_id='9acf17ec9083c4022f69eb4a37187080', meta={'name': '454_Music_of_Game_of_Thrones.txt'}}, context='...' >,\n",
        "#                  ...\n",
        "#                ]\n",
        "#     'documents': [ <Document: content_type='text', score=0.8034909798951382, meta={'name': '332_Sansa_Stark.txt'}, embedding=None, id=d1f36ec7170e4c46cde65787fe125dfe', content='\\n===\\'\\'A Game of Thrones\\'\\'===\\nSansa Stark begins the novel by being betrothed to Crown ...'>,\n",
        "#                    <Document: content_type='text', score=0.8002150354529785, meta={'name': '191_Gendry.txt'}, embedding=None, id='dd4e070a22896afa81748d6510006d2', 'content='\\n===Season 2===\\nGendry travels North with Yoren and other Night's Watch recruits, including Arya ...'>,\n",
        "#                    ...\n",
        "#                  ],\n",
        "#     'no_ans_gap':  11.688868522644043,\n",
        "#     'node_id': 'Reader',\n",
        "#     'params': {'Reader': {'top_k': 5}, 'Retriever': {'top_k': 5}},\n",
        "#     'query': 'Who is the father of Arya Stark?',\n",
        "#     'root_node': 'Query'\n",
        "# }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "Rm0mVQ48p3s8"
      },
      "outputs": [],
      "source": [
        "# ...or use a util to simplify the output\n",
        "# Change `minimum` to `medium` or `all` to raise the level of detail\n",
        "print_answers(prediction, details=\"minimum\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "1B4PlYRtp3s8"
      },
      "source": [
        "## About us\n",
        "\n",
        "This [Haystack](https://github.com/deepset-ai/haystack/) notebook was made with love by [deepset](https://deepset.ai/) in Berlin, Germany\n",
        "\n",
        "We bring NLP to the industry via open source!  \n",
        "Our focus: Industry specific language models & large scale QA systems.  \n",
        "  \n",
        "Some of our other work: \n",
        "- [German BERT](https://deepset.ai/german-bert)\n",
        "- [GermanQuAD and GermanDPR](https://deepset.ai/germanquad)\n",
        "- [FARM](https://github.com/deepset-ai/FARM)\n",
        "\n",
        "Get in touch:\n",
        "[Twitter](https://twitter.com/deepset_ai) | [LinkedIn](https://www.linkedin.com/company/deepset-ai/) | [Slack](https://haystack.deepset.ai/community/join) | [GitHub Discussions](https://github.com/deepset-ai/haystack/discussions) | [Website](https://deepset.ai)\n",
        "\n",
        "By the way: [we're hiring!](https://www.deepset.ai/jobs)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "Tutorial1_Basic_QA_Pipeline.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}